{
  "114": {
    "inputs": {
      "b1": 1.1,
      "b2": 1.1500000000000001,
      "s1": 0.85,
      "s2": 0.35000000000000003,
      "model": [
        "159",
        0
      ]
    },
    "class_type": "FreeU_V2",
    "_meta": {
      "title": "FreeU_V2"
    }
  },
  "118": {
    "inputs": {
      "ckpt_name": "realisticVisionV60B1_v51HyperVAE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "134": {
    "inputs": {
      "width": 1048,
      "height": 816,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "136": {
    "inputs": {
      "samples": [
        "230",
        0
      ],
      "vae": [
        "118",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "143": {
    "inputs": {
      "image": "controlnet.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "145": {
    "inputs": {
      "sharpen_radius": 1,
      "sigma": 0.4,
      "alpha": 0.3,
      "image": [
        "136",
        0
      ]
    },
    "class_type": "ImageSharpen",
    "_meta": {
      "title": "ImageSharpen"
    }
  },
  "159": {
    "inputs": {
      "lora_01": "None",
      "strength_01": 0.5,
      "lora_02": "None",
      "strength_02": 0.73,
      "lora_03": "None",
      "strength_03": 0.34,
      "lora_04": "None",
      "strength_04": 1,
      "model": [
        "118",
        0
      ],
      "clip": [
        "118",
        1
      ]
    },
    "class_type": "Lora Loader Stack (rgthree)",
    "_meta": {
      "title": "Lora Loader Stack (rgthree)"
    }
  },
  "183": {
    "inputs": {
      "preprocessor": "LineArtPreprocessor",
      "resolution": 1024,
      "image": [
        "143",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "186": {
    "inputs": {
      "images": [
        "183",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "209": {
    "inputs": {
      "images": [
        "293",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "216": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_lineart_fp16.safetensors"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "219": {
    "inputs": {
      "strength": 0.9,
      "start_percent": 0,
      "end_percent": 0.9,
      "positive": [
        "235",
        0
      ],
      "negative": [
        "235",
        1
      ],
      "control_net": [
        "216",
        0
      ],
      "image": [
        "183",
        0
      ],
      "timestep_kf": [
        "224",
        1
      ],
      "weights_override": [
        "224",
        0
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply",
    "_meta": {
      "title": "Apply Advanced ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "224": {
    "inputs": {
      "base_multiplier": 0.808,
      "flip_weights": false,
      "uncond_multiplier": 0.3
    },
    "class_type": "ScaledSoftControlNetWeights",
    "_meta": {
      "title": "Scaled Soft Weights ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "230": {
    "inputs": {
      "seed": 354757691473652,
      "steps": 6,
      "cfg": 2,
      "sampler_name": "dpmpp_sde",
      "scheduler": "exponential",
      "denoise": 1,
      "model": [
        "274",
        0
      ],
      "positive": [
        "219",
        0
      ],
      "negative": [
        "219",
        1
      ],
      "latent_image": [
        "243",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "231": {
    "inputs": {
      "image": "mask.png",
      "channel": "alpha",
      "upload": "image"
    },
    "class_type": "LoadImageMask",
    "_meta": {
      "title": "Load Image (as Mask)"
    }
  },
  "232": {
    "inputs": {
      "image_gen_width": 1024,
      "image_gen_height": 1024,
      "resize_mode": "Just Resize"
    },
    "class_type": "HintImageEnchance",
    "_meta": {
      "title": "Enchance And Resize Hint Images"
    }
  },
  "233": {
    "inputs": {
      "mask": [
        "231",
        0
      ]
    },
    "class_type": "InvertMask",
    "_meta": {
      "title": "InvertMask"
    }
  },
  "234": {
    "inputs": {
      "image": "ComfyUI_temp_itpyt_00007_.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "235": {
    "inputs": {
      "noise_mask": true,
      "positive": [
        "272",
        0
      ],
      "negative": [
        "273",
        0
      ],
      "vae": [
        "118",
        2
      ],
      "pixels": [
        "277",
        0
      ],
      "mask": [
        "233",
        0
      ]
    },
    "class_type": "InpaintModelConditioning",
    "_meta": {
      "title": "InpaintModelConditioning"
    }
  },
  "243": {
    "inputs": {
      "amount": 1,
      "samples": [
        "235",
        2
      ]
    },
    "class_type": "RepeatLatentBatch",
    "_meta": {
      "title": "Repeat Latent Batch"
    }
  },
  "244": {
    "inputs": {
      "text": [
        "259",
        0
      ],
      "speak_and_recognation": true,
      "clip": [
        "254",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "245": {
    "inputs": {
      "seed": 876632572477290,
      "steps": 5,
      "cfg": 2,
      "sampler_name": "euler_ancestral",
      "scheduler": "AYS SDXL",
      "denoise": 0.6,
      "preview_method": "none",
      "vae_decode": "true",
      "model": [
        "269",
        0
      ],
      "positive": [
        "248",
        0
      ],
      "negative": [
        "248",
        1
      ],
      "latent_image": [
        "246",
        0
      ],
      "optional_vae": [
        "254",
        2
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "246": {
    "inputs": {
      "version": "SDXL",
      "upscale": 1.5,
      "latent": [
        "255",
        0
      ]
    },
    "class_type": "NNLatentUpscale",
    "_meta": {
      "title": "NNLatentUpscale"
    }
  },
  "247": {
    "inputs": {
      "control_net_name": "controlnetxlCNXL_xinsirTile.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "248": {
    "inputs": {
      "strength": 0.9,
      "start_percent": 0,
      "end_percent": 0.8,
      "positive": [
        "281",
        0
      ],
      "negative": [
        "281",
        1
      ],
      "control_net": [
        "256",
        0
      ],
      "image": [
        "249",
        0
      ],
      "timestep_kf": [
        "252",
        1
      ],
      "weights_override": [
        "252",
        0
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply",
    "_meta": {
      "title": "Apply Advanced ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "249": {
    "inputs": {
      "preprocessor": "HEDPreprocessor",
      "resolution": 1024,
      "image": [
        "145",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "252": {
    "inputs": {
      "base_multiplier": 0.9,
      "uncond_multiplier": 1
    },
    "class_type": "ACN_ScaledSoftControlNetWeights",
    "_meta": {
      "title": "Scaled Soft Weights ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "253": {
    "inputs": {
      "text": [
        "262",
        0
      ],
      "speak_and_recognation": true,
      "clip": [
        "254",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "254": {
    "inputs": {
      "ckpt_name": "ponyRealism_V22Hyper4SVAE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "255": {
    "inputs": {
      "pixels": [
        "145",
        0
      ],
      "vae": [
        "254",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "256": {
    "inputs": {
      "name": "controlnet++_sdxl_promax.safetensors",
      "control_type": "hed/pidi/scribble/ted"
    },
    "class_type": "ACN_ControlNet++LoaderSingle",
    "_meta": {
      "title": "Load ControlNet++ Model (Single) ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "259": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "false",
      "text_a": [
        "287",
        0
      ],
      "text_b": [
        "278",
        0
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "262": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "false",
      "text_a": [
        "288",
        0
      ],
      "text_b": [
        "278",
        1
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "263": {
    "inputs": {
      "samples": [
        "245",
        3
      ],
      "vae": [
        "254",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "269": {
    "inputs": {
      "scale": 3,
      "model": [
        "254",
        0
      ]
    },
    "class_type": "PerturbedAttentionGuidance",
    "_meta": {
      "title": "PerturbedAttentionGuidance"
    }
  },
  "272": {
    "inputs": {
      "text": [
        "278",
        0
      ],
      "speak_and_recognation": true,
      "clip": [
        "159",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "273": {
    "inputs": {
      "text": [
        "278",
        1
      ],
      "speak_and_recognation": true,
      "clip": [
        "118",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "274": {
    "inputs": {
      "scale": 3,
      "model": [
        "114",
        0
      ]
    },
    "class_type": "PerturbedAttentionGuidance",
    "_meta": {
      "title": "PerturbedAttentionGuidance"
    }
  },
  "276": {
    "inputs": {
      "images": [
        "277",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "277": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "234",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ğŸ”§ Image Resize"
    }
  },
  "278": {
    "inputs": {
      "text_positive": "A elegant blue house, morning fresh vibe, grass yard, tree background",
      "text_negative": "old, damaged architecture, dirty walls, pale color",
      "style": "sai-photographic",
      "log_prompt": "No",
      "style_name": "",
      "speak_and_recognation": true
    },
    "class_type": "SDXLPromptStyler",
    "_meta": {
      "title": "SDXL Prompt Styler"
    }
  },
  "281": {
    "inputs": {
      "strength": 0.6,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "244",
        0
      ],
      "negative": [
        "253",
        0
      ],
      "control_net": [
        "284",
        0
      ],
      "image": [
        "285",
        0
      ],
      "mask_optional": [
        "231",
        0
      ],
      "weights_override": [
        "283",
        0
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply",
    "_meta": {
      "title": "Apply Advanced ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "283": {
    "inputs": {
      "base_multiplier": 0.9,
      "uncond_multiplier": 1
    },
    "class_type": "ACN_ScaledSoftControlNetWeights",
    "_meta": {
      "title": "Scaled Soft Weights ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "284": {
    "inputs": {
      "name": "controlnet++_sdxl_promax.safetensors",
      "control_type": "inpaint/outpaint"
    },
    "class_type": "ACN_ControlNet++LoaderSingle",
    "_meta": {
      "title": "Load ControlNet++ Model (Single) ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "285": {
    "inputs": {
      "black_pixel_for_xinsir_cn": true,
      "image": [
        "145",
        0
      ],
      "mask": [
        "233",
        0
      ]
    },
    "class_type": "InpaintPreprocessor",
    "_meta": {
      "title": "Inpaint Preprocessor"
    }
  },
  "287": {
    "inputs": {
      "text": "score_9, score_8_up, score_7_up",
      "speak_and_recognation": true
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "288": {
    "inputs": {
      "text": "score_6, score_5, score_4, ",
      "speak_and_recognation": true
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "290": {
    "inputs": {
      "images": [
        "293",
        0
      ]
    },
    "class_type": "SaveImageWebsocket",
    "_meta": {
      "title": "SaveImageWebsocket"
    }
  },
  "291": {
    "inputs": {
      "noise_radius": 6,
      "preserve_edges": 0.75,
      "sharpen": 5.5,
      "ratio": 0.5,
      "image": [
        "263",
        0
      ]
    },
    "class_type": "ImageSmartSharpen+",
    "_meta": {
      "title": "ğŸ”§ Image Smart Sharpen"
    }
  },
  "292": {
    "inputs": {
      "strength": 1,
      "image": [
        "291",
        0
      ]
    },
    "class_type": "MMakerColorEnhance",
    "_meta": {
      "title": "Color Enhance"
    }
  },
  "293": {
    "inputs": {
      "black_level": 30,
      "mid_level": 120,
      "white_level": 255,
      "image": [
        "292",
        0
      ]
    },
    "class_type": "Image Levels Adjustment",
    "_meta": {
      "title": "Image Levels Adjustment"
    }
  }
}